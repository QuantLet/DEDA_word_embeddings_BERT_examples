{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data exploration"
      ],
      "metadata": {
        "id": "bhBtXxLbT6Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6w2tZlBVTT-4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # use GPU\n",
        "\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-cased\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"bert-large-cased\")\n",
        "\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "pipe = pipeline('feature-extraction', model=model, tokenizer=tokenizer, device=device)"
      ],
      "metadata": {
        "id": "d9gC4RtDp65g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fd898b-b0f9-42c7-9930-eba52fae8109"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = tokenizer.vocab\n",
        "id2vocab = dict((value, key) for key, value in vocab.items())"
      ],
      "metadata": {
        "id": "62B5qC2_qPbH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sum = lambda a, b: np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "\n",
        "def get_embedding(sentence):\n",
        "  embedding = np.array(pipe(sentence))[0]\n",
        "  encoded_dict = tokenizer.encode(sentence)\n",
        "\n",
        "  word2embedding = dict()\n",
        "\n",
        "  repeated_words = dict()\n",
        "\n",
        "  for i, e in enumerate(encoded_dict):\n",
        "    word = id2vocab[e]\n",
        "    if word in word2embedding:\n",
        "      word2embedding[word].append(embedding[i])\n",
        "    else:\n",
        "      word2embedding[word] = [embedding[i]]\n",
        "\n",
        "  return word2embedding"
      ],
      "metadata": {
        "id": "M4X78EQvqy3j"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_a = 'The commodity futures is traded at twenty basis points'\n",
        "sentence_b = 'A commodity futures contract is an agreement to buy or sell a particular commodity at a future date'\n",
        "sentence_c = 'Like English, German has a future perfect tense that is used to talk about what will in the future be a past event'\n",
        "\n",
        "a = get_embedding(sentence_a)['future'][0] # The tokenizer break down futures into future and ##s\n",
        "b = get_embedding(sentence_b)['future'][0] # Take the first future's embedding (there are two \"future\" in sentence_b)\n",
        "c = get_embedding(sentence_c)['future'][0]\n",
        "\n",
        "print('a vs b', cos_sum(a,b))\n",
        "print('a vs c', cos_sum(a,c))\n",
        "print('b vs c', cos_sum(b,c))\n"
      ],
      "metadata": {
        "id": "fSDHCPdeWDNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff27b049-2109-47bf-9bc8-d3f34e25bfa1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a vs b 0.9628126261283041\n",
            "a vs c 0.8273704534093114\n",
            "b vs c 0.8151347365201804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_a = 'The spot price of gold is very volatile'\n",
        "sentence_b = 'The margin is calculated using the spot price of gold'\n",
        "sentence_c = 'I spot a theft running out of a store'\n",
        "\n",
        "a = get_embedding(sentence_a)['spot'][0]\n",
        "b = get_embedding(sentence_b)['spot'][0]\n",
        "c = get_embedding(sentence_c)['spot'][0]\n",
        "\n",
        "print('a vs b', cos_sum(a,b))\n",
        "print('a vs c', cos_sum(a,c))\n",
        "print('b vs c', cos_sum(b,c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA97MyFgXIdJ",
        "outputId": "a21133f7-5c23-47db-c7cc-783a6d349d7a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a vs b 0.9780781908739328\n",
            "a vs c 0.8350452357267761\n",
            "b vs c 0.8232886264930577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'If the head navigator needs the head, he should head this way'\n",
        "\n",
        "embedding = get_embedding(sentence)\n",
        "\n",
        "a = embedding['head'][0]\n",
        "b = embedding['head'][1]\n",
        "c = embedding['head'][2]\n",
        "\n",
        "\n",
        "print('a vs b', cos_sum(a,b))\n",
        "print('a vs c', cos_sum(a,c))\n",
        "print('b vs c', cos_sum(b,c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "she0ji0lZnSM",
        "outputId": "2dd72a78-94ad-44d1-8a54-fb21fccf75e8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a vs b 0.9551920629970923\n",
            "a vs c 0.8995614738705667\n",
            "b vs c 0.9225908007956791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'The jet leaves a jet of jet black smoke behind it'\n",
        "\n",
        "embedding = get_embedding(sentence)\n",
        "\n",
        "a = embedding['jet'][0]\n",
        "b = embedding['jet'][1]\n",
        "c = embedding['jet'][2]\n",
        "\n",
        "print('a vs b', cos_sum(a,b))\n",
        "print('a vs c', cos_sum(a,c))\n",
        "print('b vs c', cos_sum(b,c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFFy1o9sgKoU",
        "outputId": "407d5553-0c09-4c67-fe44-1bb4faeea4b3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a vs b 0.8956356534507922\n",
            "a vs c 0.9336614277150953\n",
            "b vs c 0.8939412732807073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mc9VmYK23Q6a"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}